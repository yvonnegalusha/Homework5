---
title: "Homework 5"
output: html_notebook
---

| Homework 5                     |                Data Analysis with R |
| :---                           |                                ---: |
| Due by 11:59 PM on Wed Sep 27  | Business Analytics Graduate Program |
| Submit via GitHub              |                 BAIS:6060 Fall 2023 |

# Instructions

This homework covers Module 5. Refer to the corresponding materials and
ICE (with solutions) posted on ICON. Follow all of the instructions
given on prior homeworks, referring to them as necessary.

# Exercises



## #1

The data `medicaid.csv` contains Medicaid eligibility and reimbursement
numbers for the state of Iowa by county and by date of report (monthly
over the course of several years). Use the data to create a choropleth
map showing total Medicaid reimbursements for the report date August 31,
2019. Use `ggsave(...)` to save the map in a file called `1.png`. You do
not have to improve the basic map, e.g., you do not have to add titles,
format the numbers, etc. And you don't need to upload `1.png` to GitHub;
just put the `ggsave(...)` command in this notebook.

```{r}

```

## #2

### (a)

Scrape the "Week-by-Week Games" table at [this
website](https://www.pro-football-reference.com/years/2018/games.htm),
which refers to the year 2018. Please use the `fill=TRUE` option
as shown in the module, and do not post-process the downloaded
table---except as instructed in parts (b) and (c) below. Save the table
in a data frame called `nfl`. [Hint: All the data is at the above URL.
There is no need to navigate to any other web pages.]

```{r}

```

### (b)

If the data is read correctly in part (a), then you'll notice that
some column names are repeated and some column names are the empty
string. Use the `clean_names(...)` function of the `janitor` package
to overwrite `nfl` with a new version having unique column names.
[Hint: Just use `clean_names(nfl)`, i.e., don't specify any options to
`clean_names`.]

```{r}

```

### (c)

You should also notice that several rows of `nfl` correspond to repeated
column headers at the source web page. There may also be other rows that
look like headers rather than actual data. Remove these rows without
affecting any other aspect of the data frame. [Note: Best practices
are to code this in such a way that, if you wanted to scrape 2019 data
instead, your code for this part would still work without any changes.]

```{r}

```
